{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving a Stokes equation on domains with different obstacles\n",
    "We are give a domain $\\Omega_\\chi \\subset \\R^2$ which is defined as all points $x \\in (0, 1)^2$ such that $\\chi(x) = 1$. We will mainly consider random placed circles cut out from the domain $(0, 1)^2$. Our goal is to solve the following Stokes\n",
    "equation on $\\Omega_\\chi$:\n",
    "\\begin{align*}\n",
    "    -\\mu \\Delta u - \\nabla p &= 0 &&\\text{ in } \\Omega_\\chi, \\\\\n",
    "    \\nabla \\cdot u &= 0 &&\\text{ in } \\Omega_\\chi.\n",
    "\\end{align*}\n",
    "With the boundary conditions:\n",
    "\\begin{align*}\n",
    "    u &= u_{in} &&\\text{ when } x_1 = 0, \\\\\n",
    "    (\\mu \\nabla u + p) \\cdot n &= 0 &&\\text{ when } x_1 = 1, \\\\\n",
    "    u &= 0 &&\\text{ everywhere else on } \\partial \\Omega_\\chi.\n",
    "\\end{align*}\n",
    "Here, $u_{in}$ is a given inflow profile.\n",
    "\n",
    "Our goal is to learn the solution operator that maps the domain $\\Omega_\\chi$ to the solution $u$.\n",
    "\n",
    "This example shows the workflow in TorchPhysics for such a 2D problem. We will not get highly accurate results because we are working with a small dataset. This is done to keep the size of the GitHub repository small.\n",
    "Better results can be obtained with more data.\n",
    "\n",
    "The general procedure is the same as for the diffusion equation, so not many comments will be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells with 'tp_version2 (Python 3.11.7)' requires the notebook package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import torch \n",
    "import torchphysics as tp\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.tensor(np.load(\"datasets/stokes_input.npy\"), dtype=torch.float32)\n",
    "output_data = torch.tensor(np.load(\"datasets/stokes_output.npy\"), dtype=torch.float32)\n",
    "\n",
    "loc_data = torch.zeros_like(output_data)\n",
    "for i in range(loc_data.shape[1]):\n",
    "    for j in range(loc_data.shape[2]):\n",
    "        loc_data[:, j, i, 0] = i / loc_data.shape[1]\n",
    "        loc_data[:, j, i, 1] = j / loc_data.shape[2]\n",
    "\n",
    "input_data = torch.concatenate((input_data, loc_data), dim=-1)\n",
    "\n",
    "train_batch_size = 3500\n",
    "train_input = input_data[:train_batch_size]\n",
    "train_output = output_data[:train_batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one example of the data\n",
    "f, axarr = plt.subplots(1,2, figsize=(6, 10))\n",
    "plot_idx = 12\n",
    "axarr[0].imshow(train_input[plot_idx, :, :, 0], origin='lower')\n",
    "axarr[0].title.set_text(r\"Example domain\")\n",
    "axarr[1].imshow(train_output[plot_idx, :, :, 0], origin='lower')\n",
    "axarr[1].title.set_text(r\"Example solution $u_x$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TorchPhysics we have to define the input and output space like always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tp.spaces.R2(\"x\")\n",
    "Phi = tp.spaces.R3(\"phi\")\n",
    "U = tp.spaces.R2(\"u\")\n",
    "\n",
    "fn_space_input = tp.spaces.FunctionSpace(X, Phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_functionset_input = tp.domains.DataFunctionSet(fn_space_input,\n",
    "                                                    input_data)\n",
    "data_functionset_output = tp.domains.DataFunctionSet(tp.spaces.FunctionSpace(X, U),\n",
    "                                                    output_data)\n",
    "\n",
    "functionsampler_input = tp.samplers.FunctionSamplerOrdered(1500, data_functionset_input)\n",
    "# The output should be coupled to the correct input functions:\n",
    "functionsampler_output = tp.samplers.FunctionSamplerCoupled(data_functionset_output, functionsampler_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the network that learns the mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DeepONet\n",
    "# x_grid = torch.linspace(0, 1, 32)\n",
    "# point_grid = torch.permute(torch.stack(torch.meshgrid((x_grid, x_grid))), (2, 1, 0)).unsqueeze(0)\n",
    "# trunk_net = tp.models.FCTrunkNet(X, hidden=(10, 10), default_trunk_input=point_grid)\n",
    "\n",
    "# conv_network = torch.nn.Sequential(\n",
    "#     torch.nn.Conv2d(Phi.dim, 16, kernel_size=3, stride=2, padding=1),\n",
    "#     torch.nn.Tanh(),\n",
    "#     torch.nn.Conv2d(16, 1, kernel_size=3, stride=1, padding=1),\n",
    "#     torch.nn.Tanh()\n",
    "# )\n",
    "\n",
    "# branch_net = tp.models.ConvBranchNet(fn_space_input, \n",
    "#                                      convolutional_network=conv_network,\n",
    "#                                      hidden=(20, 20), grid=point_grid)\n",
    "\n",
    "\n",
    "# model = tp.models.DeepONet(trunk_net, branch_net, U, output_neurons=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FNO\n",
    "hidden_channels = 32\n",
    "\n",
    "model = tp.models.FNO(Phi, U, \n",
    "                      fourier_layers=8, \n",
    "                      hidden_channels=hidden_channels, \n",
    "                      fourier_modes=(12, 12), # Here two modes need to be set (one for each space direction) \n",
    "                      skip_connections=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_functionset_input.compute_pca(components=50)\n",
    "# data_functionset_output.compute_pca(components=50)\n",
    "\n",
    "# model = tp.models.PCANN_FC.from_fn_set(\n",
    "#     data_functionset_input, data_functionset_output, hidden=(60, 100, 200, 100, 60)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_condition = tp.conditions.OperatorCondition(module=model, \n",
    "                                                 input_function_sampler=functionsampler_input, \n",
    "                                                 output_function_sampler=functionsampler_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.005, 0.001, 0.0001]\n",
    "step_list = [2000, 20000, 20000]\n",
    "\n",
    "for i in range(len(lr_list)):\n",
    "    optim = tp.OptimizerSetting(optimizer_class=torch.optim.Adam, lr=lr_list[i])\n",
    "    solver = tp.solver.Solver([data_condition], optimizer_setting=optim)\n",
    "\n",
    "    trainer = pl.Trainer(devices=1, accelerator=\"gpu\",\n",
    "                        num_sanity_val_steps=0,\n",
    "                        benchmark=True,\n",
    "                        max_steps=step_list[i], \n",
    "                        logger=False, \n",
    "                        enable_checkpointing=False)\n",
    "\n",
    "    trainer.fit(solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One would need more data to get better results, but for this example we now evaluate and obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = input_data[train_batch_size:]\n",
    "test_output = output_data[train_batch_size:]\n",
    "\n",
    "if isinstance(model, tp.models.DeepONet):\n",
    "    model_output = model(branch_inputs=tp.spaces.Points(test_input, Phi)).as_tensor\n",
    "else:\n",
    "    model_output = model(tp.spaces.Points(test_input, Phi)).as_tensor\n",
    "\n",
    "rel_error = torch.max(torch.abs(model_output - test_output)) / torch.max(test_output)\n",
    "\n",
    "print(f\"Relative error: {rel_error*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one example of data\n",
    "plot_idx = 2 # <- value between 0 and 499\n",
    "\n",
    "f, axarr = plt.subplots(1,4, figsize=(20, 6))\n",
    "img = axarr[0].imshow(test_input[plot_idx, :, :, 0], origin='lower')\n",
    "axarr[0].title.set_text(r\"Test domain\")\n",
    "plt.colorbar(img, ax=axarr[0], shrink=0.75)\n",
    "\n",
    "sol_min = torch.min(test_output[plot_idx])\n",
    "sol_max = torch.max(test_output[plot_idx])\n",
    "img = axarr[1].imshow(torch.linalg.norm(test_output[plot_idx], dim=-1), vmin=sol_min, vmax=sol_max, origin='lower')\n",
    "axarr[1].title.set_text(r\"Expected mag. of $u$\")\n",
    "plt.colorbar(img, ax=axarr[1], shrink=0.75)\n",
    "\n",
    "img = axarr[2].imshow(torch.linalg.norm(model_output[plot_idx].detach(), dim=-1), vmin=sol_min, vmax=sol_max, origin='lower')\n",
    "axarr[2].title.set_text(r\"Predicted mag. of $u$\")\n",
    "plt.colorbar(img, ax=axarr[2], shrink=0.75)\n",
    "\n",
    "error = torch.linalg.norm(model_output[plot_idx].detach() - test_output[plot_idx], dim=-1)\n",
    "img = axarr[3].imshow(error, cmap='jet', origin='lower')\n",
    "axarr[3].title.set_text(r\"Difference\")\n",
    "plt.colorbar(img, ax=axarr[3], shrink=0.75)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp_version2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
