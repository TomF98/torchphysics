{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup 2: The DeepRitz-Method\n",
    "\n",
    "While PINNs usually utilize the strong formulation of the PDE, there are other concepts that use different formulations of the PDE for training the network, one of them is the DeepRitz method. There, the energy formulation\n",
    "of the problem is used.\n",
    "\n",
    "Let us consider the following simple Laplace equation with a singularity at (0, 0):\n",
    "\\begin{align*}\n",
    "    -\\Delta u &= 1 \\text{ in } \\Omega, \\\\\n",
    "    u &= 0 \\text{ on } \\partial \\Omega,\n",
    "\\end{align*} \n",
    "\n",
    "with $\\Omega=([-1, 1] \\times [-1, 1]) \\setminus ([0, 1] \\times \\{0\\})$.\n",
    "\n",
    "Then the energy functional for this problem is given by:\n",
    "\\begin{equation}\n",
    "    E(v) = \\int_\\Omega \\frac{1}{2}\\|\\nabla v\\|^2 \\text{d}x\n",
    "\\end{equation}\n",
    "The solution $u$ of the strong formulation minimizes the energy functional, namely $E(u) \\leq E(v)$ for all $v$ in the corresponding function space.\n",
    "\n",
    "The DeepRitz method still tries to learn the solution $u$, but now minimizes $E$ in the training instead of using the strong formulation. To include the boundary condition, the functional also is extended:\n",
    "\\begin{equation}\n",
    "    E(v) = \\int_\\Omega \\frac{1}{2}\\|\\nabla v\\|^2 \\text{d}x + \\int_{\\partial\\Omega} \\frac{1}{2}\\|v\\|^2 \\text{d}o\n",
    "\\end{equation}\n",
    "\n",
    "The following cells, show the usage of DeepRitz in TorchPhysics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is for GPU selection. Please execute.\n",
    "import pathlib\n",
    "import os\n",
    "user = int(str(pathlib.Path().resolve())[22:24])\n",
    "if user <= 21: \n",
    "    gpu_device = str(user % 7) # moriarty\n",
    "else: gpu_device = str(user % 4) # neptuno\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchphysics as tp \n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "X = tp.spaces.R1('x') \n",
    "Y = tp.spaces.R1('y')\n",
    "U = tp.spaces.R1('u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the square [-1, 1] x [-1, 1] \n",
    "square = \n",
    "line = tp.domains.Interval(X, 0, 1) * tp.domains.Point(Y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create the sampler. For DeepRitz we need to approximate the integral, therefore one usually needs more points\n",
    "# then in the PINN approach to get a good estimate.\n",
    "# But since in the energy functional the derivatives are of lower order, this generally does not lead to memory problems.\n",
    "inner_sampler = tp.samplers.RandomUniformSampler(square, n_points=100000) \n",
    "\n",
    "bound_sampler = tp.samplers.RandomUniformSampler(square.boundary, n_points=40000)\n",
    "bound_sampler += tp.samplers.RandomUniformSampler(line, n_points=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classic DeepRitz method uses a ResNet-architecture instead of a FCN. This is also implemented and used here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add the input and output space\n",
    "model = tp.models.DeepRitzNet(input_space=, output_space=, width=20, depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation of the mathematical equations is handled similar to the PINN approach. For each integral in the energy functional, we define a condition.\n",
    "\n",
    "Instead of a *PINNCondition*, we now use a *DeepRitzCondition*. While the *PINNCondition* compute the mean squared error over the output of the residual function, the *DeepRitzCondition* only sums up the output to approximate the interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The integral for the boundary\n",
    "def bound_residual(u):\n",
    "    return u**2\n",
    "\n",
    "bound_cond = tp.conditions.DeepRitzCondition(module=model, sampler=bound_sampler, \n",
    "                                             integrand_fn=bound_residual, weight=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The integral for the inner part.\n",
    "# TODO: Following the implementation in the above cell, complete the condition below:\n",
    "#       Hint: to compute the norm over a batch of vectors called v, the call\n",
    "#       torch.sum(v, dim=1, keepdim=True) is useful.\n",
    "def energy_residual(u, x, y):\n",
    "    return\n",
    "\n",
    "pde_cond = tp.conditions.DeepRitzCondition(..., weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name             | Type       | Params\n",
      "------------------------------------------------\n",
      "0 | train_conditions | ModuleList | 3.4 K \n",
      "1 | val_conditions   | ModuleList | 0     \n",
      "------------------------------------------------\n",
      "3.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.4 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df36ef876cb4728ae2fe7a55a0895c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomfre/miniconda3/envs/bosch/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tomfre/miniconda3/envs/bosch/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b2f181ee7047a8966f5ce0be602497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ed1b7d5f8f43c9810c6a1a6cce041c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim = tp.OptimizerSetting(optimizer_class=torch.optim.Adam, lr=0.001)\n",
    "solver = tp.solver.Solver(train_conditions=[bound_cond, pde_cond], optimizer_setting=optim)\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, # or None if CPU is used\n",
    "                     max_steps=4000, # number of training steps\n",
    "                     logger=False,\n",
    "                     benchmark=True,\n",
    "                     checkpoint_callback=False)\n",
    "                     \n",
    "trainer.fit(solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use different optimizer algorithms, like LBFGS to may get better convergence.\n",
    "\n",
    "One point we have to keep in mind, is to fix the inputs of the neural network for LBFGS to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name             | Type       | Params\n",
      "------------------------------------------------\n",
      "0 | train_conditions | ModuleList | 3.4 K \n",
      "1 | val_conditions   | ModuleList | 0     \n",
      "------------------------------------------------\n",
      "3.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.4 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdf252e6a5748958e99c3fc709cb674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065a0ddcf6f642d19e3bfd6d616011c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29878664f043434a85f42f7560e52485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim = tp.OptimizerSetting(optimizer_class=torch.optim.LBFGS, lr=0.05, \n",
    "                            optimizer_args={'max_iter': 2, 'history_size': 100})\n",
    "\n",
    "pde_cond.sampler = pde_cond.sampler.make_static() \n",
    "bound_cond.sampler = bound_cond.sampler.make_static() \n",
    "solver = tp.solver.Solver(train_conditions=[bound_cond, pde_cond], optimizer_setting=optim)\n",
    "\n",
    "trainer = pl.Trainer(gpus=1,\n",
    "                     max_steps=2000, # number of training steps\n",
    "                     logger=False,\n",
    "                     benchmark=True,\n",
    "                     checkpoint_callback=False)\n",
    "                     \n",
    "trainer.fit(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sampler = tp.samplers.PlotSampler(plot_domain=square, n_points=640, device='cuda')\n",
    "fig = tp.utils.plot(model, lambda u : u, plot_sampler, plot_type='contour_surface')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bosch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
