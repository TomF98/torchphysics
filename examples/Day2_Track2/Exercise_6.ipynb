{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Allen-Cahn Problem\n",
    "Next, we considere the following differential equation:\n",
    "\\begin{align*}\n",
    "    \\epsilon \\Delta u + (u^3-u)&= f &&\\text{ in } (0,1)^2, \\\\\n",
    "    n \\cdot \\nabla u &= 0 &&\\text{ on } \\partial (0,1)^2.\n",
    "\\end{align*}\n",
    "Instead of learning the mapping $f \\mapsto u$, we instead want to learn the inverse mapping $u \\mapsto f$. For a data driven approach to most straightforward idea is to just exchange the roles of the input and output data!\n",
    "So our network now gets $u$ as an input and should return the coressponding $f$.\n",
    "\n",
    "We try this with the PCA-Net idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import torch \n",
    "import torchphysics as tp\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/localdata/tomfre/AllenCahn_data2\"\n",
    "output_f = torch.load(f\"{save_path}/input_data.pt\")\n",
    "input_u = torch.load(f\"{save_path}/output_data.pt\")\n",
    "\n",
    "print(\"Available data points:\", len(input_u))\n",
    "print(\"Shape of data:\", input_u.shape)\n",
    "\n",
    "# Plot one example of the data\n",
    "plot_idx = 0\n",
    "\n",
    "f, axarr = plt.subplots(1, 2, figsize=(7, 3))\n",
    "axarr[0].imshow(input_u[plot_idx, :, :], origin='lower', extent=[0,1,0,1])\n",
    "axarr[0].title.set_text(r\"Example solution $u$\")\n",
    "axarr[1].imshow(output_f[plot_idx, :, :], origin='lower', extent=[0,1,0,1])\n",
    "axarr[1].title.set_text(r\"Example $f$\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spaces are the same as always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tp.spaces.R2(\"x\")\n",
    "F = tp.spaces.R1(\"f\")\n",
    "U = tp.spaces.R1(\"u\")\n",
    "fn_space_F = tp.spaces.FunctionSpace(X, F)\n",
    "fn_space_U = tp.spaces.FunctionSpace(X, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing:\n",
    "total_data = len(input_u)\n",
    "train_N = int(0.9*total_data)\n",
    "\n",
    "# TODO: Build the training and test set, as in the other examples\n",
    "train_f = ...\n",
    "train_u = ...\n",
    "\n",
    "test_f = ...\n",
    "test_u = ...\n",
    "\n",
    "# TODO: Define the FunctionSets (Remeber that the roles of u and f are switched now!)\n",
    "data_functionset_input = tp.domains.DataFunctionSet(..., ...)\n",
    "data_functionset_output = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next sampling as always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "functionsampler_input = tp.samplers.FunctionSamplerRandomUniform(4000, data_functionset_input)\n",
    "functionsampler_output = tp.samplers.FunctionSamplerCoupled(data_functionset_output, functionsampler_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to choose the number of principal components for our input and output data. \n",
    "Use the next cell to iteratively choose a fitting number, such that the smallest component you have is around the order $10^{-3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find a fitting size of the PCA, such that the smallest components are in the order of 10^(-3).\n",
    "data_functionset_input.compute_pca(components=5)\n",
    "data_functionset_output.compute_pca(components=5)\n",
    "\n",
    "\n",
    "# We may want to analyze the size of the principal components:\n",
    "_, S_in, _ = data_functionset_input.pca\n",
    "_, S_out, _ = data_functionset_output.pca\n",
    "\n",
    "f, axarr = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axarr[0].plot(S_in)\n",
    "axarr[0].title.set_text(r\"Principal components of input function $u$\")\n",
    "axarr[0].set_yscale(\"log\")\n",
    "axarr[0].grid()\n",
    "axarr[1].plot(S_out)\n",
    "axarr[1].title.set_text(r\"Principal components of output function $f$\")\n",
    "axarr[1].set_yscale(\"log\")\n",
    "axarr[1].grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the network and data condition as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tp.models.PCANN_FC.from_fn_set(\n",
    "    data_functionset_input, data_functionset_output, hidden=(50, 50, 50, 50)\n",
    ")\n",
    "\n",
    "data_condition = tp.conditions.OperatorCondition(module=model, \n",
    "                                                 input_function_sampler=functionsampler_input, \n",
    "                                                 output_function_sampler=functionsampler_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6]\n",
      "/home/tomfre/miniconda3/envs/tp_version2/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:256: Found unsupported keys in the lr scheduler dict: {'gamma', 'step_size'}. HINT: remove them from the output of `configure_optimizers`.\n",
      "\n",
      "  | Name             | Type       | Params\n",
      "------------------------------------------------\n",
      "0 | train_conditions | ModuleList | 14.0 K\n",
      "1 | val_conditions   | ModuleList | 0     \n",
      "------------------------------------------------\n",
      "14.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.0 K    Total params\n",
      "0.056     Total estimated model params size (MB)\n",
      "/home/tomfre/miniconda3/envs/tp_version2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=254` in the `DataLoader` to improve performance.\n",
      "/home/tomfre/miniconda3/envs/tp_version2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=254` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10000/10000 [01:00<00:00, 166.21it/s, train/loss=0.00466]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10000/10000 [01:00<00:00, 166.21it/s, train/loss=0.00466]\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = torch.optim.lr_scheduler.StepLR\n",
    "\n",
    "optim = tp.OptimizerSetting(optimizer_class=torch.optim.Adam, lr=0.001,\n",
    "                            scheduler_class=lr_scheduler, \n",
    "                            scheduler_args={\"step_size\": 2000, \"gamma\":0.2})\n",
    "solver = tp.solver.Solver([data_condition], optimizer_setting=optim)\n",
    "\n",
    "trainer = pl.Trainer(devices=1, accelerator=\"gpu\",\n",
    "                    num_sanity_val_steps=0,\n",
    "                    benchmark=True,\n",
    "                    max_steps=10000, \n",
    "                    logger=False, \n",
    "                    enable_checkpointing=False)\n",
    "\n",
    "trainer.fit(solver)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, check the model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error: 25.295454025268555 %\n"
     ]
    }
   ],
   "source": [
    "model_output = model(test_u).as_tensor.detach()\n",
    "\n",
    "rel_error = torch.norm(model_output - test_f, p=2, dim=(1,2,3))\n",
    "rel_error /= torch.norm(test_f, p=2, dim=(1,2,3))\n",
    "rel_error = torch.mean(torch.sqrt(rel_error))\n",
    "\n",
    "print(f\"Relative error: {rel_error*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one example of the test data\n",
    "plot_idx = 145\n",
    "\n",
    "\n",
    "def plot_fn(plot_idx, test_f, test_u, model_output):\n",
    "    _, axarr = plt.subplots(1, 4, figsize=(12, 3))\n",
    "\n",
    "    vmin, vmax = torch.min(test_f[plot_idx]), torch.max(test_f[plot_idx])\n",
    "\n",
    "    img = axarr[0].imshow(test_u[plot_idx, :, :], origin='lower', extent=[0,1,0,1])\n",
    "    axarr[0].title.set_text(r\"Input $u$\")\n",
    "    plt.colorbar(img, ax=axarr[0], shrink=0.75)\n",
    "\n",
    "    img=axarr[1].imshow(test_f[plot_idx, :, :], vmin=vmin, vmax=vmax, origin='lower', extent=[0,1,0,1])\n",
    "    axarr[1].title.set_text(r\"Expected $f$\")\n",
    "    plt.colorbar(img, ax=axarr[1], shrink=0.75)\n",
    "\n",
    "    img=axarr[2].imshow(model_output[plot_idx, :, :], vmin=vmin, vmax=vmax, origin='lower', extent=[0,1,0,1])\n",
    "    axarr[2].title.set_text(r\"Predicted $f$\")\n",
    "    plt.colorbar(img, ax=axarr[2], shrink=0.75)\n",
    "\n",
    "    img=axarr[3].imshow(torch.abs(model_output[plot_idx, :, :]-test_f[plot_idx, :, :]), \n",
    "                    cmap=\"jet\", origin='lower', extent=[0,1,0,1])\n",
    "    axarr[3].title.set_text(r\"Difference\")\n",
    "    plt.colorbar(img, ax=axarr[3], shrink=0.75)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_fn(plot_idx, test_f, test_u, model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was now the case for non-noisy data. We could ask ourselfs, what happens if we only have noisy solution data $u$ available?\n",
    "To this end let us test our model with noisy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.01*torch.randn_like(test_u)\n",
    "\n",
    "model_output = model(test_u+noise).as_tensor.detach()\n",
    "\n",
    "rel_error = torch.norm(model_output - test_f, p=2, dim=(1,2,3))\n",
    "rel_error /= torch.norm(test_f, p=2, dim=(1,2,3))\n",
    "rel_error = torch.mean(torch.sqrt(rel_error))\n",
    "\n",
    "print(f\"Relative error: {rel_error*100} %\")\n",
    "print(\"Example plot:\")\n",
    "plot_fn(plot_idx, test_f, test_u+noise, model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that our trained model is not stable when exposed to noise.\n",
    "One way to address this issue is to include noise directly during training. Let’s add noise to the original data and retrain the model.\n",
    "Copy the following code into the cell where we load the data, and then run everything again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_f = torch.load(f\"{save_path}/input_data.pt\")\n",
    "#input_u = torch.load(f\"{save_path}/output_data.pt\")\n",
    "#\n",
    "# <- TODO: Add \"input_u += 0.01*torch.randn_like(input_u)\" in the second cell of the notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp_version2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
