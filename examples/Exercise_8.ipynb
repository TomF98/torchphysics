{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepONet: Learning the Solution Operator\n",
    "Here, we use TorchPhysics and the DeepONet approach to solve the wave-equation for different intial conditions f.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\partial_t^2 u &= 0.5 \\, \\partial_x^2 u, &&\\text{ in } I_x \\times I_t, \\\\\n",
    "    u &= 0 , &&\\text{ on } \\partial I_x \\times I_t, \\\\\n",
    "    \\partial_t u(\\cdot, 0) &= 0 , &&\\text{ in } I_x, \\\\\n",
    "    u(\\cdot, 0) &= f(x) , &&\\text{ in } I_x,\n",
    "\\end{align*}\n",
    "with $I_x = [0, 2\\pi]$ and $I_t = [0, 5]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchaudio==0.13.0\n",
    "!pip install torchvision==0.14.0\n",
    "!pip install torchphysics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like always, we start by defining all parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchphysics as tp\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "\n",
    "# Here all parameters are defined:\n",
    "t_min, t_max = 0.0, 5.0\n",
    "x_min, x_max = 0.0, 2 * math.pi\n",
    "c = 0.5\n",
    "c_root = math.sqrt(c)\n",
    "\n",
    "# Size of the data set created for training\n",
    "dataset_size = 6000\n",
    "\n",
    "# Number of time points for discretization of D and training\n",
    "N_t = 25\n",
    "N_x = 200\n",
    "\n",
    "# Training parameters\n",
    "train_iterations = 2500\n",
    "learning_rate = 1.e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify our example, we will consider three different types of initial conditions. These are:\n",
    "\\begin{align*}\n",
    "    f_1(x) &= k_1 (x - x_{min}) (x_{max} - x) / 9.0 \\\\\n",
    "    f_2(x) &= (k_1 \\sin(x) + k_2 \\sin(2x) + k_3 \\sin(3x)) / 3.0 \\\\\n",
    "    f_3(x) &= f_1(x) + f_2(x)\n",
    "\\end{align*}\n",
    "Here, $k_1, k_2, k_3$ are different random parameters that lead to different initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three types of initial conditions:\n",
    "def f1(x, k1, k2, k3):\n",
    "    return k1 * (x - x_min) * (x_max - x) / 9.0\n",
    "\n",
    "def f2(x, k1, k2, k3):\n",
    "    return (k1 * torch.sin(x) + k2 * torch.sin(2*x) + k3 * torch.sin(3*x)) / 3.0\n",
    "\n",
    "def f3(x, k1, k2, k3):\n",
    "    return f1(x, k1, k2, k3) + f2(x, k1, k2, k3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a dataset of initial function, we have to sample different parameters $k_1, k_2, k_3$. This can be done with TorchPhysics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter spaces\n",
    "K1 = tp.spaces.R1('k1')\n",
    "K2 = tp.spaces.R1('k2')\n",
    "K3 = tp.spaces.R1('k3')\n",
    "\n",
    "# Parameter intervals\n",
    "I_k1 = tp.domains.Interval(K1, 0.5, 1.0)\n",
    "I_k2 = tp.domains.Interval(K2, -1.0, 1.0)\n",
    "I_k3 = tp.domains.Interval(K3, -1.0, 1.0)\n",
    "\n",
    "# Parameter sampler\n",
    "param_sampler = tp.samplers.RandomUniformSampler(I_k1*I_k2*I_k3, n_points=dataset_size)\n",
    "\n",
    "# Create parameter samples\n",
    "params = param_sampler.sample_points().as_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell handles the creation of the training data. You don't have to understand the procedure in detail, for a given initial condition. The method computes the expected solution at different time and space points.\n",
    "\n",
    "You can just run the cell and proceed to next ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(N_t, N_x, params, Fourier_N=20, integral_N=1000):\n",
    "    time_points = torch.linspace(t_min, t_max, N_t)\n",
    "    space_points = torch.linspace(x_min, x_max, N_x)\n",
    "    integral_points = torch.linspace(x_min, x_max, integral_N)\n",
    "\n",
    "    u_tensor = torch.zeros((len(params), N_t, N_x))\n",
    "    f_tensor = torch.zeros((len(params), N_x))\n",
    "    b_coeff = torch.zeros((len(params), Fourier_N))\n",
    "    f_list = [f1, f2, f3]\n",
    "    for i in range(len(params)):\n",
    "        f_evaluated = f_list[i%3](integral_points, *params[i])\n",
    "        \n",
    "        # compute coefficients of Fourier representation of f\n",
    "        for k in range(Fourier_N):\n",
    "            b_coeff[i, k] = torch.trapezoid(f_evaluated * torch.sin((k+1)/2.0 * integral_points))\n",
    "        \n",
    "        # create branch input and solution\n",
    "        f_tensor[i, :] = f_list[i%3](space_points, *params[i])\n",
    "    \n",
    "    b_coeff *= 2.0/(integral_N - 1.0)\n",
    "\n",
    "    space_points_repeat = space_points.reshape(1, -1).repeat((len(params), 1))\n",
    "\n",
    "    for j in range(N_t):\n",
    "        for k in range(Fourier_N):\n",
    "            u_tensor[:, j, :] += b_coeff[:, k:k+1] * torch.cos(c_root*(k+1)/2.0*time_points[j]) \\\n",
    "                                    *torch.sin((k+1)/2.0 * space_points_repeat)  \n",
    "    \n",
    "    return time_points, space_points, u_tensor, f_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling **create_dataset** we can create for each given parameter combination the solution $u$. The output is:\n",
    "\n",
    " - **time_points**: An equidistant time grid with $N_t$ points, where the solution has been computed.\n",
    " - **space_points**: An equidistant space grid with $N_x$ points, where the solution has been computed.\n",
    " - **u_data**: A tensor of the shape (len(params), N_t, N_x), that contains the solution for each parameter at each time and  space coordinate.\n",
    " - **f_data**: A tensor of the shape (len(params), N_x), containing the initial condition for each parameter set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_points, space_points, u_data, f_data = create_dataset(N_t, N_x, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the solution for a given parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "example_idx = 121 # between 0 and dataset_size\n",
    "\n",
    "print(\"Plot one example of the dataset:\")\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt_idx = 1\n",
    "\n",
    "for j in [0.0, (N_t-1)/4, (N_t-1)/2, 3*(N_t-1)/4, N_t-1]:\n",
    "    plt.subplot(1, 5, plt_idx)\n",
    "    plt.plot(space_points, u_data[example_idx, int(j), :])\n",
    "    plt.grid()\n",
    "    plt.title(\"t = \" + str(time_points[int(j)].item()))\n",
    "    if plt_idx == 1:\n",
    "        plt.plot(space_points, f_data[example_idx], linestyle=\"--\")\n",
    "        plt.legend([\"Solution u\", \"Initial value\"])\n",
    "    plt_idx += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the data in a training and test set. The training set will be seen by the neural network while training. The test set will be used to evaluate the performance of the network on unseen data.\n",
    "\n",
    "We want to use, at the start, 50% of our data in the training. Set the constant below to the corresponding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size = int(0.5 * dataset_size)\n",
    "\n",
    "# Split data:\n",
    "u_tensor_train = u_data[:train_data_size]\n",
    "f_tensor_train = ...\n",
    "u_tensor_test = u_data[train_data_size:]\n",
    "f_tensor_test = ...\n",
    "\n",
    "### TODO: Bonus task (after you tried to train the network once without noice)\n",
    "### Study how the learned solution behaves, if we add noise to the training data:\n",
    "#noise = 0.05\n",
    "#u_tensor_train += noise * torch.max(torch.abs(u_tensor_train)) * torch.randn_like(u_tensor_train)\n",
    "#f_tensor_train += noise * torch.max(torch.abs(f_tensor_train)) * torch.randn_like(f_tensor_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of TorchPhysics Part\n",
    "Next, we start with the TorchPhysics part. The first definitions are known and similiar to the other examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tp.spaces.R1('') # input variable\n",
    "X = tp.spaces.R1('') # input variable\n",
    "U = tp.spaces.R1('') # output variable\n",
    "F = tp.spaces.R1('') # function name for the initial values\n",
    "\n",
    "\n",
    "# Domain\n",
    "int_x = tp.domains.Interval(X, x_min, x_max)\n",
    "int_t = tp.domains.Interval(T, t_min, t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Branch net of the DeepONets gets a function as an input. This function belongs to a given space, \n",
    "# that we define at the start. The space is similar to the spaces above, but it also knows the input values\n",
    "# of the functions belong to this space:\n",
    "Fn_space = tp.spaces.FunctionSpace(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we build our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the Trunk net.\n",
    "# Add the correct input and set the size of the hidden layers \n",
    "# to (20, 30, 30, 30, 30, 40).\n",
    "trunk_net  = tp.models.FCTrunkNet(input_space=..., hidden=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To discretize the initial functions, we use the following sampler, that just returns our \n",
    "# space_points from above:\n",
    "discretization_grid = tp.spaces.Points(space_points.reshape(-1, 1), X)\n",
    "discretization_sampler = tp.samplers.DataSampler(...)\n",
    "\n",
    "# Branch net:\n",
    "# Add the functionspaces and set the size of the hidden layers \n",
    "# to (50, 20, 20, 20, 50).\n",
    "branch_net = tp.models.FCBranchNet(function_space=...,  \n",
    "                                   discretization_sampler=..., \n",
    "                                   hidden=...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two networks:\n",
    "output_neurons = 100 # for Trunk and Branch\n",
    "\n",
    "deep_O_net = tp.models.DeepONet(trunk_net, branch_net, \n",
    "                                output_space=..., \n",
    "                                output_neurons=output_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we have to create the trainigs condition for the DeepONet. \n",
    "# First, we collect our data into an object that loads and sends it the GPU:\n",
    "\n",
    "# First creating a meshgrid of time and space:\n",
    "input_tensor = torch.zeros((N_t*N_x, 2))\n",
    "input_tensor[:, 0] = torch.repeat_interleave(time_points, N_x)\n",
    "input_tensor[:, 1] = space_points.repeat(N_t)\n",
    "\n",
    "# We split here the branch and trunk into batches. Each training step another batch will be used.\n",
    "branch_batch_size = len(u_tensor_train) // 3\n",
    "trunk_batch_size  = len(input_tensor) // 3\n",
    "\n",
    "dataloader = tp.utils.DeepONetDataLoader(f_tensor_train.reshape(train_data_size, -1, 1), \n",
    "                                         input_tensor, \n",
    "                                         u_tensor_train.reshape(train_data_size, -1, 1), \n",
    "                                         F, T*X, U,\n",
    "                                         branch_batch_size, trunk_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above Dataloader can be used in a TorchPhysics condition. \n",
    "# Here, we just have to compare the output of the model with the expected\n",
    "# data. This is handled in the \"DeepONetDataCondition\".\n",
    "data_condition = tp.conditions.DeepONetDataCondition(module=..., \n",
    "                                                     dataloader=...,\n",
    "                                                     norm=...,\n",
    "                                                     root=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can start the training. In the examples before we used only one fixed learning rate, generally it is helpful to reduce the learning rate in the training process. \n",
    "In the following, this is done with a for-loop and by stopping and restarting the training with a different learning rate. There are more efficient ways, like schedulers, but for this simple example the for-loop is sufficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "for lr in [1.e-3, 5.e-4, 1.0e-4]:\n",
    "    optim = tp.OptimizerSetting(optimizer_class=torch.optim.Adam, lr=lr) \n",
    "    solver = tp.solver.Solver([data_condition], optimizer_setting=optim)\n",
    "\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1,\n",
    "                        num_sanity_val_steps=0,\n",
    "                        benchmark=True,\n",
    "                        max_steps=train_iterations,\n",
    "                        logger=False, \n",
    "                        enable_checkpointing=False\n",
    "                        )\n",
    "\n",
    "    trainer.fit(solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training itself was rather short, and the network has not completely converged yet, but for our small exercise this will be enough. \n",
    "\n",
    "We can check the error on the test set, that should be around 5-10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check error on test set:\n",
    "u_model = deep_O_net(tp.spaces.Points(input_tensor, T*X), f_tensor_test.reshape(-1, N_x, 1)).as_tensor\n",
    "error = torch.abs(u_model - u_tensor_test.reshape(len(f_tensor_test), -1, 1))\n",
    "print(\"Max. absolute error on test set is:\", torch.max(error).item())\n",
    "print(\"Relative error is:\", torch.max(error).item() / torch.max(torch.abs(u_tensor_test)).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the learned solution of the network and can see, that the generall behavoir is already learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot a solution:\n",
    "example_idx = 334 # between 0 and (dataset_size - train_data_size)\n",
    "\n",
    "print(\"Plot one example of the dataset:\")\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt_idx = 1\n",
    "\n",
    "branch_input = f_tensor_test[example_idx:example_idx+1].reshape(-1, N_x, 1)\n",
    "u_model = deep_O_net(tp.spaces.Points(input_tensor, T*X), branch_input).as_tensor.detach()\n",
    "\n",
    "for j in [0.0, (N_t-1)/4, (N_t-1)/2, 3*(N_t-1)/4, N_t-1]:\n",
    "    plt.subplot(1, 5, plt_idx)\n",
    "    plt.plot(space_points, u_tensor_test[example_idx, int(j), :])\n",
    "    plt.plot(space_points, u_model[0, int(j*N_x):int((j+1)*N_x)], linestyle=\"--\")\n",
    "    plt.grid()\n",
    "    plt.title(\"t = \" + str(time_points[int(j)].item()))\n",
    "    plt.legend([\"Solution u\", \"Network output\"])\n",
    "    plt_idx += 1\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bosch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
